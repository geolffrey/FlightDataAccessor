import base64
import json
import os
import pickle
import zlib

import h5py
import numpy as np
import simplejson
import six

from flightdatautilities.array_operations import merge_masks

from .legacy import Compatibility
from ..datatypes.parameter import Parameter


CURRENT_VERSION = 3
LIBRARY_VERSION = (1, 10, 1)
DATASET_OPTIONS = {'compression': 'gzip', 'compression_opts': 6}


# XXX: Should subclass container types: https://docs.python.org/2/library/collections.html#collections-abstract-base-classes
@six.python_2_unicode_compatible
class FlightDataFile(Compatibility):
    VERSION = CURRENT_VERSION
    DATASET_KWARGS = {'compression': 'gzip', 'compression_opts': 6}

    def __init__(self, x, mode='a'):
        if h5py.version.hdf5_version_tuple < LIBRARY_VERSION:
            pass  # XXX: Issue a warning?

        created = False
        # Prepare the file for reading or writing:
        if isinstance(x, h5py.File):
            self.path = os.path.abspath(x.filename)
            self.file = x
            # ...
        else:
            # XXX: Handle compressed files transparently?
            self.path = os.path.abspath(x)
            if not os.path.exists(self.path):
                created = True
            self.file = h5py.File(x, mode=mode)

        if created:
            self.file.attrs['version'] = self.VERSION

        # Handle backwards compatibility for older versions:
        if self.file.attrs.get('version', 0) >= self.VERSION:
            self.data = self.file
        else:
            if 'series' not in self.file:
                self.file.create_group('series')
            self.data = self.file['series']

    def __repr__(self):
        # XXX: Make use of six.u(), etc?
        return '<%(class)s [HDF5] (%(state)s, mode %(mode)s, %(size)d bytes, %(count)d parameters) %(path)s>' % {
            'class': self.__class__.__name__,
            'count': len(self),
            'mode': self.file.mode,
            'path': self.path,
            'size': os.path.getsize(self.path),  # FIXME: Pretty size? OSError?
            'state': 'open' if self.file.id else 'closed',
        }

    def __str__(self):
        return self.__repr__().lstrip('<').rstrip('>')

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        self.close()

    def __getitem__(self, name):
        '''Retrieve parameter data from the flight data file.'''
        return self.get_parameter(name)

    def __setitem__(self, name, parameter):
        '''Update parameter data in the flight data file.'''
        assert name == parameter.name  # FIXME: Proper exception!
        return self.set_parameter(parameter)

    def __delitem__(self, name):
        '''Remove a parameter from the flight data file.'''
        # XXX: Require key check?
        return self.delete_parameter(name)

    def __getattr__(self, name):
        '''Retrieve global file attribute handling special cases.'''
        value = self.data.attrs.get(name)
        # Handle backwards compatibility for older versions:
        if self.file.attrs.get('version', 0) >= self.VERSION:
            return value
        else:
            if name in {'reliable_frame_counter', 'reliable_subframe_counter' 'superframe_present'}:
                return None if value is None else bool(value)
            elif name in {'achieved_flight_record', 'aircraft_info'}:
                return pickle.loads(value)
            elif name in {'dependency_tree'}:
                return simplejson.loads(zlib.decompress(base64.decodestring(value)).decode('utf-8'))
            else:
                return value

    def __setattr__(self, name, value):
        '''Store global file attribute handling special cases.'''
        if name in ('file', 'path', 'data'):
            # handle __init__ assignments
            return object.__setattr__(self, name, value)

        if value is not None:
            # Handle backwards compatibility for older versions:
            if self.file.attrs.get('version', 0) >= self.VERSION:
                self.data.attrs[name] = value
            else:
                if name in {'reliable_frame_counter', 'reliable_subframe_counter', 'superframe_present'}:
                    value = int(value)
                elif name in {'achieved_flight_record', 'aircraft_info'}:
                    value = pickle.dumps(value, protocol=0)
                elif name in {'dependency_tree'}:
                    value = base64.encodestring(zlib.compress(simplejson.dumps(value, separators=(',', ':')).encode('ascii')))
                elif name in {'arinc'} and value not in {'717', '767'}:
                    raise ValueError('Unknown ARINC standard: %s.' % value)
                self.data.attrs[name] = value
        elif name in self.data.attrs:
            del self.data.attrs[name]

    def __delattr__(self, name):
        pass  # FIXME: Do we need this?

    def __contains__(self, name):
        '''Whether a parameter exists in the flight data file.'''
        return name in self.data

    def __len__(self):
        '''Count of parameters in the flight data file.'''
        return len(self.keys())

    def keys(self):
        return self.data.keys()

    def values(self):
        for name in self.data:
            yield self[name]

    def items(self):
        '''Iterate over the parameters in the flight data file.'''
        for name in self.data:
            yield name, self[name]

    def close(self):
        if self.file.id:
            self.file.flush()
            self.file.close()

    if six.PY2:
        iterkeys = keys
        iteritems = items
        itervalues = values

    def get_or_create(self, name):
        '''
        Return a h5py parameter group, if it does not exist then create it too.
        '''
        if name in self.keys():
            group = self.data[name]
        else:
            group = self.data.create_group(name)
        return group

    def get_parameter(self, name, copy_param=True):  # XXX: Add frequency kwarg.
        # TODO slicing and cache
        group = self.data[name]
        attrs = group.attrs
        data = group['data']
        name = name.split('/')[-1]

        kwargs = {}
        kwargs['frequency'] = attrs.get('frequency', 1)

        kwargs['submasks'] = {}
        if 'submasks' in attrs and 'submasks' in group.keys():
            submask_map = attrs['submasks']
            if submask_map.strip():
                submask_map = simplejson.loads(submask_map)
                for sub_name, index in submask_map.items():
                    kwargs['submasks'][sub_name] = group['submasks'][index]
                mask = merge_masks(list(kwargs['submasks'].values()))
                print 'merge_masks', mask, list(kwargs['submasks'].values())
        else:
            mask = group['mask']
            print 'group[mask]', mask

        old_mask = group['mask']
        if np.any(mask != old_mask):
            kwargs['submasks']['legacy'] = old_mask
            print 'mask', mask, old_mask
            mask |= old_mask

        array = np.ma.masked_array(data, mask=mask)

        if 'values_mapping' in attrs:
            values_mapping = attrs['values_mapping']
            if values_mapping.strip():
                mapping = simplejson.loads(values_mapping)
                kwargs['values_mapping'] = mapping

        if 'values_mapping' not in kwargs and data.dtype == np.int_:
            # Force float for non-values_mapped types.
            array = array.astype(np.float_)

        # backwards compatibility
        kwargs['source'] = attrs.get('source', bool(attrs.get('lfl', True)))
        kwargs['offset'] = attrs.get('offset', attrs.get('supf_offset', 0))
        kwargs['unit'] = attrs.get('unit', attrs.get('units'))

        kwargs['arinc_429'] = bool(attrs.get('arinc_429', False))
        kwargs['invalid'] = bool(attrs.get('invalid', False))
        kwargs['invalidity_reason'] = attrs.get('invalidity_reason', None)
        kwargs['limits'] = attrs.get('limits', None)
        kwargs['data_type'] = attrs.get('data_type', None)
        kwargs['source_name'] = attrs.get('source_name', None)
        parameter = Parameter(name, array, **kwargs)
        return parameter

    def set_parameter(self, parameter):
        attrs = (
            'source', 'source_name', 'data_type', 'arinc_429', 'frequency', 'offset', 'submasks', 'unit',
            'values_mapping', 'invalid', 'invalidity_reason', 'limits')

        param_group = self.get_or_create(parameter.name)
        if 'data' in param_group:
            del param_group['data']

        param_group.create_dataset('data', data=parameter.array.data, **self.DATASET_KWARGS)
        if getattr(parameter, 'submasks', None):
            if 'mask' in param_group:
                del param_group['mask']

            # Get array length for expanding booleans.
            submask_length = 0
            submask_map = {}
            for submask_name, submask_array in parameter.submasks.items():
                if (submask_array is None or type(submask_array) in (bool, np.bool8)):
                    continue
                submask_length = max(submask_length, len(submask_array))

            submask_map = {}
            submask_arrays = []
            not_empty = (x for x in parameter.submasks.items() if x[1] is not None)
            for index, (submask_name, submask_array) in enumerate(not_empty):
                submask_map[submask_name] = index

                # Expand booleans to be arrays.
                if type(submask_array) in (bool, np.bool8):
                    function = np.ones if submask_array else np.zeros
                    submask_array = function(submask_length, dtype=np.bool8)
                if parameter.name == 'Airspeed Selected':
                    print parameter, submask_array
                submask_arrays.append(submask_array)

            if len(submask_arrays) > 1:
                print parameter, submask_map
                print len(submask_arrays), len(list(x for x in parameter.submasks.items() if x[1] is not None))
            param_group.create_dataset('submasks', data=np.column_stack(submask_arrays), **self.DATASET_KWARGS)
            param_group.attrs['submasks'] = simplejson.dumps(submask_map)

        for attr in attrs:
            if hasattr(parameter, attr):
                value = getattr(parameter, attr)
                if value is None:
                    continue

                if attr == 'submasks':
                    value = json.dumps({i: n for i, n in enumerate(value)})
                elif attr == 'values_mapping':
                    value = json.dumps(value)

                param_group.attrs[attr] = value

    def delete_parameter(self, name):
        del self[name]

    def get_parameters(self, names):
        return (self.get_parameter(name) for name in names)

    def set_parameters(self, parameters):
        for parameter in parameters:
            self.set_parameter(parameter)

    def delete_parameters(self, names):
        for name in names:
            self.delete_parameter(name)
